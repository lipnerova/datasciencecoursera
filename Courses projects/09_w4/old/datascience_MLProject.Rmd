---
title: "Practical Machine Learning Project"
author: "Sebastien Plat"
output: 
  html_document:
    toc: yes
---

# Libraries

```{r setup, echo=FALSE,warning=FALSE,message=FALSE}
source(".\\rf_train.R")
library(pander)
library(caret)
library(knitr)
opts_chunk$set(message = F, error = F, warning = F, comment = NA, fig.align = 'center')
```


# Loading & Cleaning data

```{r, cache = TRUE, echo=FALSE}
# download archive
if (!dir.exists("data")) {
  dir.create("data")
}

if (!file.exists("data\\pml-training.csv")) {
  download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
                "data\\pml-training.csv")
}

# read archive (takes a while)
training <- read.csv("data\\pml-training.csv")
```

```{r, cache=TRUE}
# Cleaning data
# counting NA's / empty cells by column
naCount <- sapply(training, function(y) sum(length(which(is.na(y)))))
emptyCount <- sapply(training, function(y) sum(length(which(y==""))))

# there are many variables with 19216 NA's / empty cells (approx. 98% ob the observations). we will not keep them 
naVarPos <- which(naCount==19216)
emptyVarPos <- which(emptyCount==19216)

# vector of columns to remove: NAs & empty ones
# we also remove:
#  + column 1: observation number
#  + column 2: user name (we want the model to work for unknown users)
#  + column 3-7: time/window related info
colsToRemove <- c(1, 2, 3:7, naVarPos, emptyVarPos)

# we remove the unwanted columns
trainingLight <- training[, -colsToRemove]

rm(naCount, emptyCount, naVarPos, emptyVarPos, colsToRemove)
```


# Algorithms

```{r, cache=TRUE, warning=FALSE}
#parameters
ncv = 10
ntree = 35
```

```{r, cache=TRUE, warning=FALSE}
system.time(fit1 <- trainRF (trainingLight, "classe", ntree=ntree, cv=TRUE, ncv=ncv))
```

```{r, cache=TRUE, warning=FALSE}
# OOB estimate of error rate
fit1$finalModel$err.rate[ntree,1]
plot(fit1$finalModel$err.rate[,1])
```

# Var Imp

```{r, cache=TRUE, warning=FALSE}
# keeping only the most important variables
varImpFit <- as.matrix(varImp(fit1)$importance)

colsToKeep <- c("classe", names(sort(apply(varImpFit,1,max), decreasing=T))[1:10])
trainingL10 <- trainingLight[,colsToKeep]

colsToKeep <- c("classe", names(sort(apply(varImpFit,1,max), decreasing=T))[1:20])
trainingL20 <- trainingLight[,colsToKeep]

rm (varImpFit, colsToKeep)
```

```{r, cache=TRUE, warning=FALSE}
system.time(fitL10 <- trainRF (trainingL10, "classe", ntree=ntree, cv=TRUE, ncv=ncv))
system.time(fitL20 <- trainRF (trainingL20, "classe", ntree=ntree, cv=TRUE, ncv=ncv))
```

```{r, cache=TRUE, warning=FALSE}
# OOB estimate of error rate
fitL10$finalModel$err.rate[ntree,1]
fitL20$finalModel$err.rate[ntree,1]
fit1$finalModel$err.rate[ntree,1]

plot(fitL20$finalModel$err.rate[,1]) + 
  lines(fitL20$finalModel$err.rate[,1]) +
  lines(fitL10$finalModel$err.rate[,1]) +
  lines(fit1$finalModel$err.rate[,1])
```


# Smaller set

```{r, cache=TRUE, warning=FALSE}
# keeping only a small sample of the training set
set.seed(1)
inTrain <- createDataPartition(y=trainingLight$classe, p=0.1, list=FALSE)

trainingShortL10 <- trainingL10[inTrain,]
testingShortL10 <- trainingL10[-inTrain,]

trainingShortL20 <- trainingL20[inTrain,]
testingShortL20 <- trainingL20[-inTrain,]
```

```{r, cache=TRUE, warning=FALSE}
system.time(fitShortL10 <- trainRF (trainingShortL10, "classe", ntree=ntree, cv=TRUE, ncv=ncv))
system.time(fitShortL20 <- trainRF (trainingShortL20, "classe", ntree=ntree, cv=TRUE, ncv=ncv))
```

```{r, cache=TRUE, warning=FALSE}
# OOB estimate of error rate
fitL10$finalModel$err.rate[ntree,1]
fitL20$finalModel$err.rate[ntree,1]
fitShortL10$finalModel$err.rate[ntree,1]
fitShortL20$finalModel$err.rate[ntree,1]
fit1$finalModel$err.rate[ntree,1]

plot(fitL20$finalModel$err.rate[,1]) + 
  lines(fitL20$finalModel$err.rate[,1]) +
  lines(fitL10$finalModel$err.rate[,1]) +
  lines(fitShortL10$finalModel$err.rate[,1]) +
  lines(fitShortL20$finalModel$err.rate[,1]) +
  lines(fit1$finalModel$err.rate[,1])

fit1$finalModel$confusion
confusionMatrix(testingShortL10$classe, predict(fitShortL10, testingShortL10))
write.table(trainingShortL10, file=".\\data\\trainingShortL10.csv", row.names=FALSE, sep=",")
write.table(testingShortL10, file=".\\data\\testingShortL10.csv", row.names=FALSE, sep=",")
```






The **Confusion Matrix** illustrates how well our final model performs for the training set examples:

```{r, cache=TRUE, warning=FALSE}
# confusion matrix
confMatrix <- modelFit$finalModel$confusion
pander(confMatrix, justify="right", round=c(0,0,0,0,0,3))
```




# Prediction on test set

Lastly, we can predict the class of the 20 test cases:

```{r, cache=TRUE, warning=FALSE}
classPredict <- as.character(predict(modelFit,newdata=testingLight))
names(classPredict) <- seq(1,20)
pander(classPredict)
```


```{r, cache=TRUE, warning=FALSE}
# confusion matrix
confMatrix <- fit1$finalModel$confusion
pander(confMatrix, justify="right", round=c(0,0,0,0,0,3))
```


