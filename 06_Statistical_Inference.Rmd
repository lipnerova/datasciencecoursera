---
title: "Statistical Inference"
output: pdf_document
---

```{r, echo=FALSE,warning=FALSE,message=FALSE}
a4width<- 8.3
a4height<- 11.7
source("D:\\datascience\\multiplot.R")
library(ggplot2)
library(dplyr)
library(reshape2)
library(manipulate) 
lambda <- 0.2
expected_mean <- 1/lambda     
```

# Exponential Distribution

## Definition

According to [Wikipedia](https://en.wikipedia.org/wiki/Exponential_distribution):

> The exponential distribution [...] is the probability distribution 
> that describes the time between events in a Poisson process, i.e. a process 
> in which events occur continuously and independently at a constant **average rate $\lambda$**.

+ Its mean is 1/ $\lambda$
+ Its standard deviation is also 1/	$\lambda$

In our example, we will use **$\lambda$=0.2**. 

## Samples mean & variance

Samples mean & sample variance are **consistent estimators** of the populations mean & variance: 
they converge to the correct value as the number of samples increases.

Let's study the distribution of 1000 averages of 40 exponentials. Fig.1 and Fig.2 show the distribution of sample mean & sample variance, plus their mean and theoretical values:

```{r, echo=FALSE}

number_of_samples <- 1000
sample_size <- 40                # 5
expected_var <- 1 / (lambda^2 * sample_size)  # 0.625

# we build our samples pool from seed 1 (to have reproducible data)
set.seed(1); mns0 = NULL; mns_var = NULL
for (i in 1 : number_of_samples) {
  sample <- rexp(sample_size, lambda)
  mns0 = c(mns0, mean(sample))
  mns_var = c(mns_var, var(sample))
}

rm (i,sample)

```

```{r, warning=FALSE, echo=FALSE,  fig.width = 0.8*a4width, fig.height = 0.3*a4height, fig.align='center'}

# plot the samples mean distribution & its mean
p1 = qplot(mns0, geom = 'blank') + 
    geom_histogram(aes(y=..density..), binwidth = 0.1, alpha=0.4) +
    geom_vline (xintercept=mean(mns0), color='salmon2', lwd=1) +
    xlab("mean") +
    ggtitle ("Fig. 1: Sample Mean PDF") +
    theme(title=element_text(size = 8, colour = 'black'),
    plot.title=element_text(face='italic', vjust=2)) +
    annotate("text", x = 8, y = 0.55, hjust = 1, size=2.5,
             label = paste("mean: ", round(mean(mns0),3),
                           "\nexpected mean: ", 1/lambda))

# plot the samples variance distribution & its mean
p2 = qplot(mns_var, geom = 'blank') + 
    geom_histogram(aes(y=..density..), binwidth = 1, alpha=0.4, lwd=1) +
    geom_vline (xintercept=mean(mns_var), color='salmon2', lwd=1) +
    xlab("variance") + xlim(0,100) +
    ggtitle ("Fig. 2: Sample Variance PDF") +
    theme(title=element_text(size = 8, colour = 'black'),
    plot.title=element_text(face='italic', vjust=2)) +
    annotate("text", x = 100, y = 0.05, hjust = 1, size=2.5,
             label = paste("variance mean: ", round(mean(mns_var),3),"\n", "expected variance mean: ", 1/lambda^2))

multiplot(p1, p2, cols=2)
rm (p1,p2,mns_var)

```

We clearly see that **their mean is close to the value they estimate**. 

\pagebreak

# Central Limit Theorem

## Definition

The **Central Limit Theorem** states that, according to the Law of Large Numbers:

> The **sample mean distribution** of iid variables (mean = $\mu$, sd = $\sigma$) will become **normal**, 
> or nearly normal, as the sample size n increases. It will be approximated by:

> **$\bar X \sim N~(\mu, \sigma^2 / n)$**

An important point is that the CLT works **even if the original distribution is not normal**.

## Example

Fig. 3 shows the PDF for our distribution ($\lambda$=0.2) vs a Normal with the same mean and standard deviation.

Fig.4 shows the empirical distribution of samples mean _(cf. Fig.1)_ VS the CLT predicted one:

+ $Est=1/\lambda = 5$ 
+ $SE_{Est}=1/(\lambda \times \sqrt{n}) = 0.625$


```{r, echo=FALSE, fig.width = 0.8*a4width, fig.height = 0.3*a4height, fig.align='center', warning=FALSE}

# CLT normal
dnorm_CLT <- function (x) {
  y <- dnorm(x, mean = expected_mean, sd = sqrt(expected_var))
  return (y)
}

p1 = qplot(x=c(0,30), geom = 'blank') + 
  stat_function(fun = dexp, arg = list(rate=lambda), aes(colour = 'Exponential'), lwd=1) +
  stat_function(fun = dnorm, arg = list(mean = 1/lambda, sd = 1/lambda), aes(colour = 'Normal'), lwd=1) +
  scale_x_continuous(breaks = seq(0,30,5)) + 
  xlab("X") + ylab("P(X)") + scale_color_discrete(name =element_blank()) +
  ggtitle ("Fig. 3: PDF - Exponential vs Normal") +
  theme(title=element_text(size = 8, colour = 'black'),
        plot.title=element_text(face='italic', vjust=2),
        legend.position='bottom')

# plot the samples distribution & theoretical mean distribution
p2 = qplot(mns0, geom = 'blank') + xlim(2.5,7.5) + ylim(0,0.7) +
  geom_line(aes(y = ..density.., colour = 'Empirical'), stat = 'density', lwd=1) +  
  geom_histogram(aes(y=..density..), binwidth = 0.1, alpha=0.4) +
  stat_function(fun = dnorm_CLT, aes(colour = 'Theoretical'), lwd=1) +
  xlab("mean") +
  scale_colour_discrete(name=element_blank()) +
  ggtitle ("Fig. 4: PDF - Samples Mean vs Normal") +
  theme(title=element_text(size = 8, colour = 'black'),
        plot.title=element_text(face='italic', vjust=2),
        legend.position='bottom')
        
multiplot(p1, p2, cols=2)
rm (p1,p2)

```

We clearly see that:

+ our exponential distribution is **not even close to being normal**
+ **the empirical distribution is very close to being normal**, as predicted by the CLT

\pagebreak

# CLT Confidence Interval

## Definition

As the distribution of sample means $\bar X$ is roughly normal (mean = $\mu$ and sd = $\sigma/\sqrt{n}$),
we have for each of our samples:

$P~(\bar X < mean - 2 sd) = P~(\bar X < \mu - 2 \sigma/\sqrt{n}) \simeq 0.025$

$P~(\bar X > mean + 2 sd) = P~(\bar X > \mu + 2 \sigma/\sqrt{n}) \simeq 0.025$

It means that:

$P~(~\bar X \in [ \mu \pm 2 \sigma/sqrt{n}]~) \simeq 0.95$

```{r, echo=FALSE, fig.width = 0.4*a4width, fig.height = 0.2*a4height, fig.align='center', warning=FALSE}

# Return dnorm(x) for 0 < x < 2, and NA for all other x
int <- 2*sqrt(expected_var)
dnorm_CLT_limit <- function(x) {
  y <- dnorm(x, mean = expected_mean, sd = sqrt(expected_var))
  y[x < expected_mean - int  |  x > expected_mean + int] <- NA
  return(y)
}

# plot the samples distribution & theoretical mean distribution
p1 = qplot(mns0, geom = 'blank') + xlim(2.5,7.5) + ylim(0,0.7) +
  geom_histogram(aes(y=..density..), binwidth = 0.1, alpha=0.4) +
  stat_function(fun = dnorm_CLT, lwd=1) +
  stat_function(fun = dnorm_CLT_limit, geom="area", fill="blue", alpha=0.2) +
  geom_vline (xintercept=expected_mean - int, lwd=0.5, lty=2) +
  geom_vline (xintercept=expected_mean + int, lwd=0.5, lty=2) +
  xlab("mean") +
  scale_colour_discrete(name="Distribution") +
  ggtitle ("Fig. 5: Samples Mean 95% Interval") +
  theme(title=element_text(size = 8, colour = 'black'),
        plot.title=element_text(face='italic', vjust=2))
        
p1

rm (p1,int,dnorm_CLT,dnorm_CLT_limit,mns0,number_of_samples,sample_size)
```

We can deduce from above that:

$P~(~\mu \in [ \bar X \pm 2 \sigma/\sqrt{n}]~) \simeq 0.95$  

\  

$\bar X \pm 2 \sigma/\sqrt{n}$ is called the **95% Confidence Interval** for $\mu$. It mean that for 95% of
our samples, this interval will include $\mu$. But **it does not mean that $\mu$ is actually in this interval**.

+ CI get wider as the coverage increases 
+ CI get narrower as the sample size increases & with less variability

 The confidence interval represents values for the population parameter for which the difference between the parameter 
 and the observed estimate is not statistically significant at the 5% level.

It means that, if the true value of the parameter lies outside the 95% confidence interval once it has been calculated, then an event has occurred which had a probability of 5% (or less) of happening by chance.

## Empirical estimation

The CLT states that: $\bullet~~mean_{Est} \simeq \mu~~\bullet~~SD_{Est} \simeq \sigma~~\bullet~~\bar X \sim N~(\mu, \sigma^2 / n)~~\bullet$ so the CI is:

$$mean_{Est} \pm ZQ_{1-\alpha/2} \times SE_{Est} = mean_{Est} \pm ZQ_{1-\alpha/2} \times \frac{SD_{Est}}{\sqrt{n}}$$


\pagebreak

# T Distribution

## Definition

The CLT works only for large enough sample sizes. For smaller ones, the Gosset's $t$ distribution is
more relevant. It is assumed the population is an iid normal (or roughly symetrical & mound-shaped): 
the t-interval does not work well with skewed data.

In that case:

$$\frac{\bar X - \mu}{S /\sqrt{n}}$$

follows a $t$-distribution with n-1 degrees of freedom _(replacing $S$ by $\sigma$ would give exactly a 
standard normal)_. Its tails are **thicker than normal**, so its Confidence Interval is **wider** for the same Confidence Level.

## Example

Back to the Exponential Distribution, Fig.6 shows the experimental sample distribution vs T vs Normal 
for different sample sizes. The $t$-distribution gets close to normal even for relatively small sample sizes.


```{r, echo=FALSE}

number_of_samples <- 1000
sample_size <- c(2,5,10,20)

# we build our samples pool from seed 1 (to have reproducible data)
set.seed(1); mns1 = NULL;
for (i in 1 : number_of_samples) {
  sample <- lapply(sample_size, function(x) {rexp(x, lambda)}) # exp dist on several sample sizes
  spmean <- sapply(sample, mean)  # vector of means
  spsd <- sapply(sample, sd)      # vector of sd
  tvalue <- (spmean - expected_mean)/(spsd/sqrt(sample_size))
  tvalue <- cbind(tvalue, sample_size)  # matrix sample mean/sample size
  mns1 <- rbind(mns1, tvalue)
}

mnsDf <- as.data.frame(mns1)
colnames (mnsDf) <- c('tvalue', 'size')
mnsDf$size <- factor(mnsDf$size)

# we build our t-distribution curves
x <- seq(-4,4,len=100)
tdist <- data.frame(x=rep(x,each=length(sample_size)),sample_size)
tdist$y <- with(tdist,dt(x,sample_size-1))
colnames (tdist) <- c('x', 'size', 'y')
tdist$size <- factor(tdist$size)

rm (i,mns1,sample,spmean,spsd)

```

```{r, echo=FALSE, fig.width = 0.65*a4width, fig.height = 0.45*a4height, fig.align='center', warning=FALSE}

# plot the samples distribution (converted to T-like) & normal & T

p1 = ggplot(mnsDf, aes(x=tvalue)) + xlim(-4,4) + 
     geom_line(aes(y = ..density.., colour = 'Empirical'), stat = 'density', lwd=0.7) +
     geom_histogram(aes(y=..density..), binwidth = 0.2, alpha=0.2) +
     stat_function(fun = dnorm, aes(colour = 'Normal'), lwd=0.7) +
     geom_line(data=tdist, aes(x,y, colour='T'), lwd=0.7) +
     facet_wrap( ~ size) +
     ggtitle ("Fig. 6: PDF - Samples Mean vs Normal vs T") +
     scale_colour_discrete(name=element_blank()) +
     theme(title=element_text(size = 8, colour = 'black'),
     plot.title=element_text(face='italic', vjust=2),
     legend.position="bottom")

p1

rm (p1,x,number_of_samples,sample_size,mnsDf,tdist,tvalue)

```

\pagebreak

# T Confidence Intervals

## Definition

T Confidence Intervals are slightly different from CLT ones:

$$mean_{Est} \pm TQ_{1-\alpha/2, n-1} \times SE_{Est} = mean_{Est} \pm TQ_{1-\alpha/2, n-1} \times \frac{SD_{Est}}{\sqrt{n}}$$


\  

## Comparizon of CLT vs T Confidence Intervals

Back to the Exponential Distribution, Fig.7 shows how CLT and T Confidence Intervals perform 
for different sample sizes.

```{r, echo=FALSE, warning=FALSE}

number_of_samples <- 1000
sample_size <- c(2,5,10,20, 40, 100, 1000)

# we build our samples pool from seed 1 (to have reproducible data)
set.seed(1); mns2 = NULL;
for (i in 1 : number_of_samples) {
  sample <- lapply(sample_size, function(x) {rexp(x, lambda)}) # exp dist on several sample sizes
  spmean <- sapply(sample, mean)                   # vector of means
  serror <- sapply(sample, sd)/sqrt(sample_size)   # vector of sd errors

  llz <- spmean - qnorm(0.975) * serror
  ulz <- spmean + qnorm(0.975) * serror
  isz <- llz < expected_mean & expected_mean < ulz

  llt <- spmean - qt(0.975, sample_size-1) * serror
  ult <- spmean + qt(0.975, sample_size-1) * serror
  ist <- llt < expected_mean & expected_mean < ult
  
  sp_value <- cbind (sample_size, spmean, isz, ist)
  mns2 <- rbind(mns2, sp_value)
}

# we convert our data in a data frame
mnsDf <- as.data.frame(mns2)
colnames (mnsDf) <- c('size', 'spmean', 'zvalue', 'tvalue')

# we calculate the % of samples for which the 95% CI actually includes the mean
mnsDfGroup <- group_by (mnsDf, size) %>%
              summarize (dist_mean = mean(spmean), dist_se = sd(spmean), zvalue = mean(zvalue), tvalue = mean(tvalue)) %>%
              mutate (zConf=paste('[', round(dist_mean - qnorm(0.975)*dist_se,3), 
                                  ',', round(dist_mean + qnorm(0.975)*dist_se,3), ']'),
                      tConf=paste('[', round(dist_mean - qt(0.975, size-1)*dist_se,3), 
                                  ',', round(dist_mean + qt(0.975, size-1)*dist_se,3), ']'))

# we melt our df to ggplot more easily
mnsDfGroupMelt <- melt (select (mnsDfGroup, size, zvalue, tvalue), id.vars=c('size'))
mnsDfGroupMelt$size <- factor(mnsDfGroupMelt$size)

# we show our results
print.data.frame(select (mnsDfGroup, size, zConf, tConf), row.names=FALSE, include.rownames = FALSE)

rm (i,sample_size,number_of_samples,sample,spmean,serror,llz,ulz,isz,llt,ult,ist,sp_value,mns2,mnsDf,mnsDfGroup)

```

\  

```{r, echo=FALSE, fig.width = 0.5*a4width, fig.height = 0.3*a4height, fig.align='center', warning=FALSE}

# plot the samples distribution (converted to T-like) & normal & T

p1 = ggplot(mnsDfGroupMelt, aes(x=size, y=value, group=variable, colour=variable)) + geom_line(lwd=1) + 
     xlab('Sample Size') + ylab('Percentage of CI that include the mean') + ylim(0.5,1) +
     geom_hline(yintercept = 0.95) +
     #geom_line(aes(y = ..density.., colour = 'Empirical'), stat = 'density', lwd=1) +
     #geom_histogram(aes(y=..density..), binwidth = 0.2, alpha=0.2) +
     #stat_function(fun = dnorm, aes(colour = 'Normal'), lwd=1) +
     #geom_line(data=tdist, aes(x,y, colour='T'), lwd=1) +
     ggtitle ("Fig. 7: 95% Confidence Interval - Normal vs T") +
     scale_colour_discrete(name="Distribution") +
     theme(title=element_text(size = 8, colour = 'black'),
     plot.title=element_text(face='italic', vjust=2))

p1

rm(p1,expected_mean,expected_var,lambda,mnsDfGroupMelt)

```

The $T$-interval is, as expected, **much more reliable for small sample sizes**. The behaviour of the two methods converge when the sample size increases.

\pagebreak

# Comparing two populations

## Definition

$T$-intervals are very useful to compare two populations. 

> Confidence intervals of difference between populations that **do not contain 0** imply 
> that there is a **statistically significant difference** between the populations.

## Example

A classic example is the sleep data analyzed in Gosset's Biometrika paper.
Fig.8 shows the increase in hours of sleep for 10 patients on two soporific drugs: 

```{r, echo=FALSE, fig.width = 0.5*a4width, fig.height = 0.3*a4height, fig.align='center', warning=FALSE}

data(sleep)

# add slope for each ID
sleep$group <- factor(sleep$group )
sleep <- sleep %>% group_by(ID) %>%
         mutate(slope = (extra[group==2] - extra[group==1])/(2-1))


# plot
p1 = ggplot(sleep, aes(x=group, y=extra, group=ID, colour=ID)) + xlab("Drug N°") + ylab("Extra hours of sleep") +
     geom_point() + geom_line() +
     ggtitle ("Fig. 8: Increase in hours of sleep - drug N°1 vs N°2") +
     theme(title=element_text(size = 8, colour = 'black'),
     plot.title=element_text(face='italic', vjust=2)) +
     scale_colour_discrete(name="Patient ID") +
     scale_size(guide = FALSE)

p1

rm (p1)

```

It seems that drug N°2 is more efficient than drug N°1. To confirm this hypothesis, we can take a $t$-test
to calculate the T Confidence Interval of their difference.

```{r}

g1 <- sleep$extra[sleep$group==1]; g2 <- sleep$extra[sleep$group==2]
ttest <-t.test(g2, g1, paired = TRUE)
result <- as.data.frame (cbind(round(ttest$conf, 3)[1], 
                               round(ttest$conf, 3)[2], 
                               round(ttest$p.value, 5)))
names(result) <- c("Lconf", "Uconf", "p.value")
print(result)

```

The T Confidence Interval does not include 0 and P < 0.005, so **drug N°2 is statistically more efficient than
drug N°1**.

\pagebreak

## Generalization

A generalization of the $t$-test can be used for comparing independant groups (different sample sizes, etc.) with or 
without equal variance. Performing it on Gosset's sleep data gives the following results:

```{r, echo=FALSE}

# create an empty data frame  
df <- data.frame(paired=logical(),
                 eqVar=logical(),
                 Lconf=numeric(),
                 Uconf=numeric(),
                 p.value=numeric()) 

for (myTest in list(c(TRUE,TRUE), c(FALSE,TRUE), c(FALSE,FALSE))) {
  ttest <- t.test(g2, g1, paired = myTest[1], var.equal=myTest[2])
  result <- as.data.frame (cbind(myTest[1],
                                 myTest[2],
                                 round(ttest$conf, 3)[1], 
                                 round(ttest$conf, 3)[2], 
                                 round(ttest$p.value, 5)))
  
  df <- rbind(df, result)
}

names(df) <- c("Paired", "EqVar", "Lconf", "Uconf", "p.value")
print(df)

rm (result,df,g1,g2,ttest,myTest)

```

By omitting the information that the two populations are paired, the results become less clear
(but equal & unequal variance give a very similar CI). We can easily see why by studing the two distributions, as shown
Fig.9.

```{r, echo=FALSE, fig.width = 0.4*a4width, fig.height = 0.3*a4height, fig.align='center', warning=FALSE}

# plot
p1 = ggplot(sleep, aes(x=group, y=extra,fill=group)) +
     geom_boxplot() + 
     #scale_x_discrete(labels=c("0.50", "1.00", "2.00")) +
     ggtitle ("Fig. 9:  Increase in hours of sleep \ndrug N°1 vs N°2 as independent groups") +
     theme(title=element_text(size = 8, colour = 'black'),
           plot.title=element_text(face='italic', vjust=2),
           axis.title.x=element_blank())

p1

rm(p1,sleep)

```

\pagebreak

# Hypothesis Testing

## Principle

Hypothesis testing is the use of statistics to determine the **probability that a given hypothesis is true**. 

The usual process of hypothesis testing consists of four steps:

1. **Formulate** the null hypothesis $H_0$ and the alternative hypothesis $H_a$. Commonly:

    +  $H_0$: the observations are the result of pure chance
    +  $H_a$: the observations show a real effect combined with a component of chance variation

2. Identify a **test statistic** that can be used to assess the truth of H_0.

3. **Compute** the P-value. The **smaller** the P-value, the **stronger** the evidence **against $H_0$**.

4. **Compare** the P-value to an acceptable significance value $\alpha$. If $P\leq\alpha$:

    +  the observed effect is **statistically significant**
    +  the null hypothesis is ruled out, and the **alternative hypothesis** is **valid**

## Outcomes

There are four possible outcomes of our statistical decision process:

\  

Truth | Decide | Result |
:---:|:---:|:---|
$H_0$ | $H_0$ | Correctly accept null |
$H_0$ | $H_a$ | Type I error $\alpha$ |
$H_a$ | $H_a$ | Correctly reject null |
$H_a$ | $H_0$ | Type II error $\beta$ |


## P-value and Alpha

The P-value is:

> the probability that a test statistic at least as significant as the one observed 
> would be obtained if $H_0$ were true.

It means that $\alpha$ is the **Type I error rate** = Probability of rejecting $H_0$ when it is correct.


\pagebreak

## Example: sample mean

Let's suppose we have a sample of mean = $\bar X$ and standard deviation $S$. Our hypothesis $H_0$ is that the mean
of the population from which our sample is drawn is $\mu_0$:

$H_0:\mu = \mu_0$

Under $H_0$, the sample mean distribution $Est \sim N~(\mu_0,S/\sqrt{n})$. We want to measure how far from $\mu_0$ our
sample mean is: if it is too far away to be statistically likely, we can reasonably reject $H_0$. Otherwise, we will **fail 
to reject** $H_0$.

To challenge $H_0$, we will consider the Test Statistic:

$$TS = \frac{\bar{X} - \mu_0}{S/\sqrt{n}}$$

This reduces the Hypothesis Testing to the following table, where the TS is called the **Z-score**:

\  

Alternate Hyp.   | Reject $H_0$ if |
:---------------:|:----------------|
$\mu < \mu_0$    |$TS \leq Z_{\alpha} = -Z_{1 - \alpha}$
$\mu \neq \mu_0$ |$|TS| \geq Z_{1 - \alpha / 2}$
$\mu > \mu_0$    |$TS \geq Z_{1 - \alpha}$


For small sample sizes, the $T$-test is performed the same way:

Alternate Hyp.   | Reject $H_0$ if |
:---------------:|:----------------|
$\mu < \mu_0$    |$TS \leq t_{\alpha, n-1} = -t_{1 - \alpha, n-1}$
$\mu \neq \mu_0$ |$|TS| \geq t_{1 - \alpha / 2, n-1}$
$\mu > \mu_0$    |$TS \geq t_{1 - \alpha, n-1}$

\  

## Link with Confidence Interval

When we test $H_0: \mu = \mu_0$ versus $H_a: \mu \neq \mu_0$, we fail to reject $H_0$ for all values $\bar X$
where $TS \leq Z_{1 - \alpha / 2}$. This set is a $(1-\alpha)100\%$ confidence interval for $\mu$.

The same works in reverse; if a $(1-\alpha)100\%$ interval contains $\mu_0$, then we **fail  to reject** $H_0$.

\pagebreak

# Power

A type II error is **failing to reject $H_0$ when it's false**. Its probability is usually called $\beta$.

Its opposite is the **probability of rejecting $H_0$ when it is false**. It is called **power**: $power = 1- \beta$.

Reminder: $\alpha$ is the **probability of rejecting $H_0$ when it is correct**.

## Example

Let's consider the hypothesis $H_a: \mu = \mu_a > \mu_0$. In that case **(same for $t$-tests:** `power.t.test`):

$$\alpha = P\left(TS > Z_{1-\alpha} ~;~ \mu = \mu_0 \right)~~\bullet~~Power = P\left(TS > Z_{1-\alpha} ~;~ \mu = \mu_a \right)$$

Power increases as:

+ $\alpha$ increases
+ n gets larger
+ $\mu_a$ gets further away from $\mu_0$
+ S decreases

\  

Fig.10-11 show an example of $H_a: \mu_a < \mu_0$ and an example of $H_a: \mu_a > \mu_0$. The vertical black bar 
shows the measured mu value below or above which we can statistically reject $H_0$ ($\alpha = 0.05$), and the corresponding
power (that depends on the value of $\mu_a$).

\  

```{r,echo=FALSE,warning=FALSE}

mu0 = 30 
myplot <- function(sigma, mua, n, alpha, type) {
  
  # calculate parameters
  xitc = mu0 + qnorm(1 - alpha) * sigma/sqrt(n)
  yitc = mu0 - qnorm(1 - alpha) * sigma/sqrt(n)
  muL = min(mu0,mua)
  muU = max(mu0,mua)
  mumin = muL - 6; mumax = muU + 6

  # calculate points under the normals
  df <- dplyr::data_frame(
          x = seq(mumin, mumax, length = 1000),
          alphaL = ifelse(x < yitc, dnorm(x, mean = mu0, sd = sigma/sqrt(n)), NA),
          powerL = ifelse(x < yitc, dnorm(x, mean = mua, sd = sigma/sqrt(n)), NA),
          alphaG = ifelse(x > xitc, dnorm(x, mean = mu0, sd = sigma/sqrt(n)), NA),
          powerG = ifelse(x > xitc, dnorm(x, mean = mua, sd = sigma/sqrt(n)), NA)
  )
  
  g = ggplot(df, aes(x)) + xlab("mu")

  # draw normals of mean mu0 and mua
  g = g + stat_function(fun = dnorm, args = list(mean = mu0, sd = sigma/sqrt(n)), aes(colour='mu0'), lwd = 1)
  g = g + stat_function(fun = dnorm, args = list(mean = mua, sd = sigma/sqrt(n)), aes(colour='muA'), lwd = 1)
  
  # draw area under the normals, depending on the comp type
  if (type=='G') {
    g = g + geom_area(aes(y = alphaG, fill="alpha"), alpha=0.4, na.rm = TRUE)
    g = g + geom_area(aes(y = powerG, fill="power"), alpha=0.2, na.rm = TRUE)
    g = g + geom_vline(xintercept = xitc, size = 1)
    z = qnorm(1 - alpha) 
    alphaP = pnorm(xitc, mean = mu0, sd = sigma/sqrt(n), lower.tail = FALSE)
    powerP = pnorm(xitc, mean = mua, sd = sigma/sqrt(n), lower.tail = FALSE)
  }
  else {
    g = g + geom_area(aes(y = alphaL, fill="alpha"), alpha=0.4, na.rm = TRUE)
    g = g + geom_area(aes(y = powerL, fill="power"), alpha=0.2, na.rm = TRUE)
    g = g + geom_vline(xintercept = yitc, size = 1)
    alphaP = pnorm(yitc, mean = mu0, sd = sigma/sqrt(n))
    powerP = pnorm(yitc, mean = mua, sd = sigma/sqrt(n))
  }
  
  # calculate power & alpha probabilities
  g = g + annotate("text", x = mumax, y = 0.25, hjust = 1, size=2.5,
             label = paste("alpha: ", round(alphaP,3),
                           "\npower: ", round(powerP,3)))
  
  g = g + scale_colour_discrete(name="Hypothesis") + scale_fill_discrete(name="Probability")
  g = g + theme(title=element_text(size = 8, colour = 'black'),
                plot.title=element_text(face='italic', vjust=2),
                legend.position='bottom',
                axis.title.y=element_blank())
  g
}

p1 = myplot(6,26,16,0.05,'L')
p1 = p1 + ggtitle ("Fig. 10: alpha vs power; muA = mu0 - 4 ")

p2 = myplot(6,32,16,0.05,'G')
p2 = p2 + ggtitle ("Fig. 11: alpha vs power; mu1 = mu0 + 2 ")

multiplot(p1, p2, cols=2)
rm (p1,p2)

#manipulate(myplot(sigma, mua, n, alpha),
#           sigma = slider(1, 10, step = 1, initial = 4),
#           mua = slider(30, 35, step = 1, initial = 32),
#           n = slider(1, 50, step = 1, initial = 16),
#           alpha = slider(0.01, 0.1, step = 0.01, initial = 0.05))

rm (mu0,myplot) # comment out when using manipulate

```


